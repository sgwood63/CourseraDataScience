Selection: 6

| Attempting to load lesson dependencies...

| Package ‘ggplot2’ loaded correctly!

| Package ‘jpeg’ loaded correctly!

  |                                                                                                      |   0%

| Variance. (Slides for this and other Data Science courses may be found at github
| https://github.com/DataScienceSpecialization/courses/. If you care to use them, they must be downloaded as a
| zip file and viewed locally. This lesson corresponds to 06_Statistical_Inference/05_Variance.)

...

  |==                                                                                                    |   2%

| In this lesson, we'll discuss variances of distributions which, like means, are useful in characterizing
| them. While the mean characterizes the center of a distribution, the variance and its square root, the
| standard deviation, characterize the distribution's spread around the mean. As the sample mean estimates the
| population mean, so the sample variance estimates the population variance.

...

  |====                                                                                                  |   4%

| The variance of a random variable, as a measure of spread or dispersion, is, like a mean, defined as an
| expected value. It is the expected squared distance of the variable from its mean. Squaring the distance
| makes it positive so values less than and greater than the mean are treated the same. In mathematical terms,
| if X comes from a population with mean mu, then

...

  |======                                                                                                |   6%

| Var(X) = E( (X-mu)^2 ) = E( (X-E(X))^2 ) = E(X^2)-E(X)^2

...

  |========                                                                                              |   8%

| So variance is the difference between two expected values. Recall that E(X), the expected value of a random
| variable from the population, is mu, the mean of that population.

...

  |==========                                                                                            |  10%

| Higher variance implies more spread around a mean than lower variance.

...

  |============                                                                                          |  12%

| Finally, it's easy to show from the definition and the linearity of expectations that, if a is a constant,
| then Var(aX)=a^2*Var(X). This will come in handy later.

...

  |==============                                                                                        |  13%

| If you're interested, here's the proof. You might have to stretch out your plot window to make it clearer.

...

  |================                                                                                      |  15%

| Let's practice computing the variance of a dice roll now. First we need to compute E(X^2). From the
| definition of expected values, this means we'll take a weighted sum over all possible values of X^2. The
| weight is the probability of X occurring.

...

  |==================                                                                                    |  17%

| For convenience, we've defined a 6-long vector for you, dice_sqr, which holds the squares of the integers 1
| through 6. This will give us the X^2 values. Look at it now.

> dice_sqr
[1]  1  4  9 16 25 36

| That's correct!

  |====================                                                                                  |  19%

| Now we need weights. For these we can use any of the three PDF's, (dice_fair, dice_high, and dice_low) we
| defined in the previous lesson. Using R's ability to multiply vectors componentwise and its function 'sum' we
| can easily compute E(X^2) for any of these dice. Simply sum the product dice_sqr * PDF.  Try this now with
| dice_fair and put the result in a variable ex2_fair.

> ex2_fair <- dice_sqr * dice_fair

| Almost! Try again. Or, type info() for more options.

| Type 'ex2_fair <- sum(dice_fair * dice_sqr)' at the command prompt.

> ex2_fair <- sum(dice_sqr * dice_fair)

| All that practice is paying off!

  |======================                                                                                |  21%

| Recall that the expected value of a fair dice roll is 3.5. Subtract the square of that from ex2_fair to
| compute the sample variance.

> ex2_fair - 3.5^2
[1] 2.916667

| You got it right!

  |========================                                                                              |  23%

| Now use a similar approach to compute the sample variance of dice_high in one step. Sum the appropriate
| product and subtract the square of the mean. Recall that edh holds the expected value of dice_high.

> sum(dice_sqr * dice_high) - edh^2
[1] 2.222222

| Excellent job!

  |==========================                                                                            |  25%

| Note that when we talk about variance we're using square units. Because it is often more useful to use
| measurements in the same units as X we define the standard deviation of X as the square root of Var(X).

...

  |===========================                                                                           |  27%

| Here's a figure from the slides. It shows several normal distributions all centered around a common mean 0,
| but with different standard deviations. As you can see from the color key on the right, the thinner the bell
| the smaller the standard deviation and the bigger the standard deviation the fatter the bell.

...

  |=============================                                                                         |  29%

| Just as we distinguished between a population mean and a sample mean we have to distinguish between a
| population variance sigma^2 and a sample variance s^2. They are defined similarly but with a slight
| difference. The sample variance is defined as the sum of n squared distances from the sample mean divided by
| (n-1), where n is the number of samples or observations. We divide by n-1 because this is the number of
| degrees of freedom in the system. The first n-1 samples or observations are independent given the mean. The
| last one isn't independent since it can be calculated from the sample mean used in the formula.

...

  |===============================                                                                       |  31%

| In other words, the sample variance is ALMOST the average squared deviation from the sample mean.

...

  |=================================                                                                     |  33%

| As with the sample mean, the sample variance is also a random variable with an associated population
| distribution. Its expected value or mean is the population variance and its distribution gets more
| concentrated around the population variance with more data. The sample standard deviation is the square root
| of the sample variance.

...

  |===================================                                                                   |  35%

| To illustrate this point, consider this figure which plots the distribution of 10000 variances, Each variance
| was computed on a sample of standard normals of size 10. The vertical line indicates the standard deviation
| 1.

...

  |=====================================                                                                 |  37%

| Here we do the same experiment but this time (the taller lump) each of the 10000 variances is over 20
| standard normal samples. We've plotted over the first plot (the shorter lump) and you can see that the
| distribution of the variances is getting tighter and shifting closer to the vertical line.

...

  |=======================================                                                               |  38%

| Finally, we repeat the experiment using 30 samples for each of the 10000 variances. You can see that with
| more data, the distribution gets more concentrated around the population variance it is trying to estimate.

...

  |=========================================                                                             |  40%

| Now recall that the means of unbiased estimators equal the values they're trying to estimate. We can infer
| from the above that the sample variance is an unbiased estimator of population variance.

...

  |===========================================                                                           |  42%

| Recall that the average of random samples from a population is itself a random variable with a distribution
| centered around the population mean. Specifically, E(X') = mu, where X' represents a sample mean and mu is
| the population mean.

...

  |=============================================                                                         |  44%

| We can show that, if the population is infinite, the variance of the sample mean is the population variance
| divided by the sample size. Specifically, Var(X') = sigma^2 / n. Let's work through this in four short steps.

...

  |===============================================                                                       |  46%

| Which of the following does Var(X') equal? Here X' represents the sample mean and 'Sum(X_i)' represents the
| sum of the n samples X_1,...X_n. Assume these samples are independent.

1: sigma
2: Var(1/n * Sum(X_i))
3: E(1/n * Sum(X_i))
4: mu

Selection: 2

| You are doing so well!

  |=================================================                                                     |  48%

| Which of the following does Var(1/n * Sum(X_i)) equal?

1: sigma/n
2: mu/n^2
3: 1/n^2*E(Sum(X_i))
4: 1/n^2*Var(Sum(X_i))

Selection: 4

| You are amazing!

  |===================================================                                                   |  50%

| Recall that Var is an expected value and expected values are linear. Also recall that our samples X_1,
| X_2,...,X_n are independent. What does Var(Sum(X_i)) equal?

1: E(mu)
2: Sum(Var(X_i))
3: E(Sum(X_i))
4: Var(sigma)

| By linearity, the variance of the sum equals the sum of the variance.

1: E(Sum(X_i))
2: Var(sigma)
3: E(mu)
4: Sum(Var(X_i))

Selection: 4

| That's correct!

  |=====================================================                                                 |  52%

| Finally, each X_i comes from a population with variance sigma^2. What does Sum(Var(X_i)) equal? As before,
| Sum is taken over n values.

1: n*(sigma)^2
2: n*E(mu)
3: (n^2)*Var(sigma)
4: n*mu

Selection: 1

| You got it right!

  |=======================================================                                               |  54%

| So we've shown that Var(X')=Var(1/n*Sum(X_i))=(1/n^2)*Var(Sum(X_i))=(1/n^2)*Sum(sigma^2)=sigma^2/n for
| infinite populations when our samples are independent.

...

  |=========================================================                                             |  56%

| The standard deviation of a statistic is called its standard error, so the standard error of the sample mean
| is the square root of its variance.

...

  |===========================================================                                           |  58%

| We just showed that the variance of a sample mean is sigma^2 / n and we estimate it with s^2 / n. It follows
| that its square root, s / sqrt(n), is the standard error of the sample mean.

...

  |=============================================================                                         |  60%

| The sample standard deviation, s, tells us how variable the population is, and s/sqrt(n), the standard error,
| tells us how much averages of random samples of size n from the population vary. Let's see this with some
| simulations.

...

  |===============================================================                                       |  62%

| The R function rnorm(n,mean,sd) generates n independent (hence uncorrelated) random normal samples with the
| specified mean and standard deviation. The defaults for the latter are mean 0 and standard deviation 1. Type
| the expression sd(apply(matrix(rnorm(10000),1000),1,mean)) at the prompt.

> sd(apply(matrix(rnorm(10000),1000),1,mean)) 
[1] 0.3129702

| Great job!

  |=================================================================                                     |  63%

| This returns the standard deviation of 1000 averages, each of a sample of 10 random normal numbers with mean
| 0 and standard deviation 1. The theory tells us that the standard error, s/sqrt(n), of the sample means
| indicates how much averages of random samples of size n (in this case 10) vary. Now compute 1/sqrt(10) to see
| if it matches the standard deviation we just computed with our simulation.

> 1/sqrt(10)
[1] 0.3162278

| Keep up the great work!

  |===================================================================                                   |  65%

| Pretty close, right? Let's try a few more. Standard uniform distributions have variance 1/12. The theory
| tells us the standard error of means of independent samples of size n would have which standard error?

1: 12/sqrt(n)
2: 1/sqrt(12*n)
3: I haven't a clue
4: 1/(12*sqrt(n))

Selection: 
Selection: 2

| Not quite right, but keep trying.

| In this case s is the sqrt(1/12). Divide this by sqrt(n).

1: 1/sqrt(12*n)
2: I haven't a clue
3: 1/(12*sqrt(n))
4: 12/sqrt(n)

Selection: 3

| You are quite good my friend!

  |=====================================================================                                 |  67%

| Compute 1/sqrt(120). This would be the standard error of the means of uniform samples of size 10.

> 1/sqrt(120)
[1] 0.09128709

| Perseverance, that's the answer.

  |=======================================================================                               |  69%

| Now check it as we did before. Use the expression sd(apply(matrix(runif(10000),1000),1,mean)).

> sd(apply(matrix(runif(10000),1000),1,mean))
[1] 0.0929478

| You are amazing!

  |=========================================================================                             |  71%

| Pretty close again, right? Poisson(4) are distributions with variance 4; what standard error would means of
| random samples of n Poisson(4) have?

1: 2*sqrt(n)
2: I haven't a clue
3: 1/sqrt(2*n)
4: 2/sqrt(n)

Selection: 3

| Almost! Try again.

| In this case s is 2. Divide this by sqrt(n).

1: 1/sqrt(2*n)
2: 2*sqrt(n)
3: 2/sqrt(n)
4: I haven't a clue

Selection: 3

| All that practice is paying off!

  |===========================================================================                           |  73%

| We'll do another simulation to test the theory. First, assume you're taking averages of 10 Poisson(4) samples
| and compute the standard error of these means. Use the formula you just chose.

> 2/sqrt(10)
[1] 0.6324555

| You're the best!

  |============================================================================                          |  75%

| Now check it as we did before. Use the expression sd(apply(matrix(rpois(10000,4),1000),1,mean)).

> sd(apply(matrix(rpois(10000,4),1000),1,mean))
[1] 0.653752

| You are doing so well!

  |==============================================================================                        |  77%

| Like magic, right? One final test. Fair coin flips have variance 0.25; means of random samples of n coin
| flips have what standard error?

1: 1/sqrt(2*n)
2: 2*sqrt(n)
3: I haven't a clue
4: 1/(2*sqrt(n))
5: 2/sqrt(n)

Selection: 4

| All that practice is paying off!

  |================================================================================                      |  79%

| You know the drill. Assume you're taking averages of 10 coin flips and compute the standard error of these
| means with the theoretical formula you just picked.

> 1/(2*sqrt(10))
[1] 0.1581139

| Keep working like that and you'll get there!

  |==================================================================================                    |  81%

| Now check it as we did before. Use the expression sd(apply(matrix(sample(0:1,10000,TRUE),1000),1,mean)).

> sd(apply(matrix(sample(0:1,10000,TRUE),1000),1,mean))
[1] 0.155802

| You are doing so well!

  |====================================================================================                  |  83%

| Finally, here's something interesting. Chebyshev's inequality helps interpret variances. It states that the
| probability that a random variable X is at least k standard deviations from its mean is less than 1/(k^2). In
| other words, the probability that X is at least 2 standard deviations from the mean is less than 1/4, 3
| standard deviations 1/9, 4 standard deviations 1/16, etc.

...

  |======================================================================================                |  85%

| However this estimate is quite conservative for random variables that are normally distributed, that is, with
| bell-curve distributions. In these cases, the probability of being at least 2 standard deviations from the
| mean is about 5% (as compared to Chebyshev's upper bound of 25%) and the probability of being at least 3
| standard deviations from the mean is roughly .2%.

...

  |========================================================================================              |  87%

| Suppose you had a measurement that was 4 standard deviations from the distribution's mean. What would be the
| upper bound of the probability of this happening using Chebyshev's inequality?

1: 96%
2: 6%
3: 0%
4: 11%
5: 25%

Selection: 2

| Nice work!

  |==========================================================================================            |  88%

| Now to review. The sample variance estimates what?

1: sample standard deviation
2: sample mean
3: population
4: population variance

Selection: 4

| Keep working like that and you'll get there!

  |============================================================================================          |  90%

| The distribution of the sample variance is centered at what?

1: sample standard deviation
2: population
3: population variance
4: sample mean

Selection: 4

| You're close...I can feel it! Try it again.

| What is the sample variance estimating?

1: sample mean
2: population variance
3: population
4: sample standard deviation

Selection: 2

| All that practice is paying off!

  |==============================================================================================        |  92%

| True or False - The sample variance gets more concentrated around the population variance with larger sample
| sizes

1: False
2: True

Selection: 2

| You're the best!

  |================================================================================================      |  94%

| The variance of the sample mean is the population variance divided by ?

1: n^2
2: I haven't a clue
3: n
4: sqrt(n)

Selection: 3

| Perseverance, that's the answer.

  |==================================================================================================    |  96%

| The standard error of the sample mean is the sample standard deviation s divided by ?

1: n
2: n^2
3: I haven't a clue
4: sqrt(n)

Selection: 4

| Common Distributions. (Slides for this and other Data Science courses may be found at github
| https://github.com/DataScienceSpecialization/courses/. If you care to use them, they must be downloaded as a
| zip file and viewed locally. This lesson corresponds to 06_Statistical_Inference/06_CommonDistros.)

...

  |==                                                                                                    |   2%

| Given the title of this lesson, what do you think it will cover?

1: Common Distributions
2: I haven't a clue
3: Rare Distributions
4: Common Bistros

Selection: 1

| Nice work!

  |=====                                                                                                 |   5%

| The first distribution we'll examine is the Bernoulli which is associated with experiments which have only 2
| possible outcomes. These are also called (by people in the know) binary trials.

...

  |=======                                                                                               |   7%

| It might surprise you to learn that you've probably had experience with Bernoulli trials. Which of the
| following would be a Bernoulli trial?

1: Tossing a die
2: Spinning a roulette wheel
3: Flipping a coin
4: Drawing a card from a deck

Selection: 3

| Perseverance, that's the answer.

  |=========                                                                                             |   9%

| For simplicity, we usually say that Bernoulli random variables take only the values 1 and 0. Suppose we also
| specify that the probability that the Bernoulli outcome of 1 is p. Which of the following represents the
| probability of a 0 outcome?

1: p
2: p(1-p)
3: 1-p
4: p^2

Selection: 3

| Keep working like that and you'll get there!

  |============                                                                                          |  11%

| If the probability of a 1 is p and the probability of a 0 is 1-p which of the following represents the PMF of
| a Bernoulli distribution? Recall that the PMF is the function representing the probability that X=x.

1: p*(1-p)
2: p^x * (1-p)^(1-x)
3: p^(1-x) *(1-p)*(1-x)
4: x*(1-x)

Selection: 2

| You are quite good my friend!

  |==============                                                                                        |  14%

| Recall the definition of the expectation of a random variable. Suppose we have a Bernoulli random variable
| and, as before, the probability it equals 1 (a success) is p and probability it equals 0 (a failure) is 1-p.
| What is its mean?

1: 1-p
2: p^2
3: p(1-p)
4: p

Selection: 4

| That's the answer I was looking for.

  |================                                                                                      |  16%

| Given the same Bernoulli random variable above, which of the following represents E(X^2)

1: p
2: (1-p)^2
3: 1-p
4: p(1-p)
5: p^2

Selection: 5

| You almost had it, but not quite. Try again.

| Add the two terms x^2*p(x) where x equals 0 and 1 respectively.

1: p(1-p)
2: p
3: (1-p)^2
4: 1-p
5: p^2

Selection: 2

| You are really on a roll!

  |===================                                                                                   |  18%

| Use the answers of the last two questions to find the variance of the Bernoulli random variable. Recall Var =
| E(X^2)-(E(X))^2

1: p(1-p)
2: p(p-1)
3: p^2*(1-p)^2
4: p^2-p

Selection: 1

| That's a job well done!

  |=====================                                                                                 |  20%

| Binomial random variables are obtained as the sum of iid Bernoulli trials.  Specifically, let X_1, ..., X_n
| be iid Bernoulli(p) random variables; then X = X_1 + X_2 + ... X_n is a binomial random variable. Binomial
| random variables represent the number of successes, k, out of n independent Bernoulli trials. Each of the
| trials has probability p.

...

  |=======================                                                                               |  23%

| The PMF of a binomial random variable X is the function representing the probability that X=x. In other
| words, that there are x successes out of n independent trials. Which of the following represents the PMF of a
| binomial distribution? Here x, the number of successes, goes from 0 to n, the number of trials, and
| choose(n,x) represents the binomial coefficient 'n choose x' which is the number of ways x successes out of n
| trials can occur regardless of order.

1: p^x
2: choose(n,x) * p^x * (1-p)^(n-x)
3: choose(n,x) * p^(n-x) * (1-p)^x
4: choose(n,x) * p*x*(1-p)*(1-x)

Selection: 2

| That's a job well done!

  |==========================                                                                            |  25%

| Suppose we were going to flip a biased coin 5 times. The probability of tossing a head is .8 and a tail .2.
| What is the probability that you'll toss at least 3 heads.

> choose(5,3) * 0.8^5
[1] 3.2768

| Almost! Try again. Or, type info() for more options.

| You'll have to add together 3 terms each of the form, choose(5,x)*(.8)^x*(.2)^(5-x) for x=3,4,5 .

> choose(5,3) * 0.8^3 * 0.2^(5-3)
[1] 0.2048

| Give it another try. Or, type info() for more options.

| You'll have to add together 3 terms each of the form, choose(5,x)*(.8)^x*(.2)^(5-x) for x=3,4,5 .

> choose(5,3) * 0.8^3 * 0.2^2
[1] 0.2048

| You're close...I can feel it! Try it again. Or, type info() for more options.

| You'll have to add together 3 terms each of the form, choose(5,x)*(.8)^x*(.2)^(5-x) for x=3,4,5 .

> choose(5,3)*(0.8)^3*0.2^2
[1] 0.2048

| Give it another try. Or, type info() for more options.

| You'll have to add together 3 terms each of the form, choose(5,x)*(.8)^x*(.2)^(5-x) for x=3,4,5 .

> choose(5,3)*(0.8)^3*0.2^2 + choose(5,4)*(0.8)^4*0.2^1 + choose(5,5)*(0.8)^5*0.2^0
[1] 0.94208

| You're the best!

  |============================                                                                          |  27%

| Now you can verify your answer with the R function pbinom. The quantile is 2, the size is 5, the prob is .8
| and the lower.tail is FALSE. Try it now.

> pbinom(q = 2, size = 5, prob = 0.8, lower.tail = FALSE)
[1] 0.94208

| That's the answer I was looking for.

  |==============================                                                                        |  30%

| Another very common distribution is the normal or Gaussian. It has a complicated density function involving
| its mean mu and variance sigma^2. The key fact of the density formula is that when plotted, it forms a bell
| shaped curve, symmetric about its mean mu. The variance sigma^2 corresponds to the width of the bell, the
| higher the variance, the fatter the bell. We denote a normally distributed random variable X as X ~ N(mu,
| sigma^2).

...

  |================================                                                                      |  32%

| When mu = 0 and sigma = 1 the resulting distribution is called the standard normal distribution and it is
| often labeled Z.

...

  |===================================                                                                   |  34%

| Here's a picture of the density function of a standard normal distribution. It's centered at its mean 0 and
| the vertical lines (at the integer points of the x-axis) indicate the standard deviations.

...

  |=====================================                                                                 |  36%

| Approximately 68%, 95% and 99% of the normal density lie within 1, 2 and 3 standard deviations from the mean,
| respectively. These are shown in the three shaded areas of the figure. For example, the darkest portion
| (between -1 and 1) represents 68% of the area.

...

  |=======================================                                                               |  39%

| The R function qnorm(prob) returns the value of x (quantile) for which the area under the standard normal
| distribution to the left of x equals the parameter prob. (Recall that the entire area under the curve is 1.)
| Use qnorm now to find the 10th percentile of the standard normal. Remember the argument prob must be between
| 0 and 1. You don't have to specify any of the other parameters since the default is the standard normal.

> qnorm(0.1)
[1] -1.281552

| Excellent work!

  |==========================================                                                            |  41%

| We'll see this now by drawing the vertical line at the quantile -1.281552.

...

  |============================================                                                          |  43%

| Which of the following would you expect to be the 1st percentile?

1: -1.28
2: -2.33
3: -1.0
4: 2.33
5: 0

Selection: 2

| Perseverance, that's the answer.

  |==============================================                                                        |  45%

| By looking at the picture can you say what the 50th percentile is?

> 0
[1] 0

| Your dedication is inspiring!

  |=================================================                                                     |  48%

| We can use the symmetry of the bell curve to determine other quantiles. Given that 2.5% of the area under the
| curve falls to the left of x=-1.96, what is the 97.5 percentile for the standard normal?

1: 1.96
2: -1.28
3: 2.33
4: 2

Selection: 1

| You are really on a roll!

  |===================================================                                                   |  50%

| Here are two useful facts concerning normal distributions. If X is a normal random variable with mean mu and
| variance sigma^2, i.e., X ~ N(mu,sigma^2),

...

  |=====================================================                                                 |  52%

| then the random variable Z defined as Z = (X -mu)/sigma is normally distributed with mean 0 and variance 1,
| i.e., Z ~ N(0, 1). (Z is standard normal.)

...

  |========================================================                                              |  55%

| The converse is also true. If Z is standard normal, i.e., Z ~ N(0,1), then the random variable X defined as X
| = mu + sigma*Z is normally distributed with mean mu and variance sigma^2, i.e., X ~ N(mu, sigma^2)

...

  |==========================================================                                            |  57%

| These formulae allow you to easily compute quantiles (and thus percentiles) for ANY normally distributed
| variable if you know its mean and variance. We'll show how to find the 97.5th percentile of a normal
| distribution with mean 3 and variance 4.

...

  |============================================================                                          |  59%

| Again, we can use R's qnorm function and simply specify the mean and standard deviation (the square root of
| the variance). Do this now. Find the 97.5th percentile of a normal distribution with mean 3 and standard
| deviation 2.

> qnorm(mean = 3, sd = 2, p = 97.5)
[1] NaN
Warning message:
In qnorm(mean = 3, sd = 2, p = 97.5) : NaNs produced

| That's not the answer I was looking for, but try again. Or, type info() for more options.

| Type qnorm(.975,mean=3,sd=2) at the R prompt.

> qnorm(97.5, mean = 3, sd = 2)
[1] NaN
Warning message:
In qnorm(97.5, mean = 3, sd = 2) : NaNs produced

| Not quite! Try again. Or, type info() for more options.

| Type qnorm(.975,mean=3,sd=2) at the R prompt.

> qnorm(.975, mean = 3, sd = 2)
[1] 6.919928

| Excellent job!

  |===============================================================                                       |  61%

| Let's check it using the formula above, X = mu + sigma*Z. Here we'll use the 97.5th percentile for the
| standard normal as the value Z in the formula. Recall that we previously calculated this to be 1.96. Let's
| multiply this by the standard deviation of the given normal distribution (2) and add in its mean (3) to see
| if we get a result close to the one qnorm gave us.

> 3 + 2^1.96
[1] 6.89062

| Not quite, but you're learning! Try again. Or, type info() for more options.

| Type 1.96*2 + 3 at the R prompt.

> 3 + 2*1.96
[1] 6.92

| Keep working like that and you'll get there!

  |=================================================================                                     |  64%

| Suppose you have a normal distribution with mean 1020 and standard deviation of 50 and you want to compute
| the probability that the associated random variable X > 1200. The easiest way to do this is to use R's pnorm
| function in which you specify the quantile (1200), the mean (1020) and standard deviation (50). You also must
| specify that the lower.tail is FALSE since we're asking for a probability that the random variable is greater
| than our quantile. Do this now.

> pnorm(1200, mean = 1020, sd = 50, lower.tail = FALSE)
[1] 0.0001591086

| That's correct!

  |===================================================================                                   |  66%

| Alternatively, we could use the formula above to transform the given distribution to a standard normal. We
| compute the number of standard deviations the specified number (1200) is from the mean with Z = (X
| -mu)/sigma. This is our new quantile. We can then use the standard normal distribution and the default values
| of pnorm. Remember to specify that lower.tail is FALSE.  Do this now.

> qnorm((1200-1020)/50, mean = 1020, sd = 50, lower.tail = FALSE)
[1] NaN
Warning message:
In qnorm((1200 - 1020)/50, mean = 1020, sd = 50, lower.tail = FALSE) :
  NaNs produced

| Not quite! Try again. Or, type info() for more options.

| Type pnorm((1200-1020)/50,lower.tail=FALSE) at the R prompt.

> qnorm((1200-1020)/50,  lower.tail = FALSE)
[1] NaN
Warning message:
In qnorm((1200 - 1020)/50, lower.tail = FALSE) : NaNs produced

| Not exactly. Give it another go. Or, type info() for more options.

| Type pnorm((1200-1020)/50,lower.tail=FALSE) at the R prompt.

> pnorm((1200-1020)/50,  lower.tail = FALSE)
[1] 0.0001591086

| You are doing so well!

  |======================================================================                                |  68%

| For practice, using the same distribution, find the 75% percentile. Use qnorm and specify the probability
| (.75), the mean (1020) and standard deviation (50). Since we want to include the left part of the curve we
| can use the default lower.tail=TRUE.

> qnorm(0.75, mean = 1020, sd = 50, lower.tail = FALSE)
[1] 986.2755

| Give it another try. Or, type info() for more options.

| Type qnorm(.75,mean=1020,sd=50) at the R prompt.

> qnorm(0.75, mean = 1020, sd = 50, lower.tail = TRUE)
[1] 1053.724

| You're the best!

  |========================================================================                              |  70%

| Note that R functions pnorm and qnorm are inverses. What would you expect pnorm(qnorm(.53)) to return?

> .53
[1] 0.53

| Keep working like that and you'll get there!

  |==========================================================================                            |  73%

| How about qnorm(pnorm(.53))?

> .53
[1] 0.53

| You're the best!

  |============================================================================                          |  75%

| Now let's talk about our last common distribution, the Poisson. This is, as Wikipedia tells us, "a discrete
| probability distribution that expresses the probability of a given number of events occurring in a fixed
| interval of time and/or space if these events occur with a known average rate and independently of the time
| since the last event."

...

  |===============================================================================                       |  77%

| In other words, the Poisson distribution models counts or number of event in some interval of time. From
| Wikipedia, "Any variable that is Poisson distributed only takes on integer values."

...

  |=================================================================================                     |  80%

| The PMF of the Poisson distribution has one parameter, lambda. As with the other distributions the PMF
| calculates the probability that the Poisson distributed random variable X takes the value x. Specifically,
| P(X=x)=(lambda^x)e^(-lambda)/x!. Here x ranges from 0 to infinity.

...

  |===================================================================================                   |  82%

| The mean and variance of the Poisson distribution are both lambda.

...

  |======================================================================================                |  84%

| Poisson random variables are used to model rates such as the rate of hard drive failures. We write
| X~Poisson(lambda*t) where lambda is the expected count per unit of time and t is the total monitoring time.

...

  |========================================================================================              |  86%

| For example, suppose the number of people that show up at a bus stop is Poisson with a mean of 2.5 per hour,
| and we want to know the probability that at most 3 people show up in a 4 hour period. We use the R function
| ppois which returns a probability that the random variable is less than or equal to 3. We only need to
| specify the quantile (3) and the mean (2.5 * 4). We can use the default parameters, lower.tail=TRUE and
| log.p=FALSE. Try it now.

> ppois(3, lambda = 2.5 * 4)
[1] 0.01033605

| Your dedication is inspiring!

  |==========================================================================================            |  89%

| Finally, the Poisson distribution approximates the binomial distribution in certain cases. Recall that the
| binomial distribution is the discrete distribution of the number of successes, k, out of n independent binary
| trials, each with probability p. If n is large and p is small then the Poisson distribution with lambda equal
| to n*p is a good approximation to the binomial distribution.

...

  |=============================================================================================         |  91%

| To see this, use the R function pbinom to estimate the probability that you'll see at most 5 successes out of
| 1000 trials each of which has probability .01. As before, you can use the default parameter values
| (lower.tail=TRUE and log.p=FALSE) and just specify the quantile, size, and probability.

> pbinom(5, size = 1000, p= 0.1)
[1] 2.556546e-38

| Not exactly. Give it another go. Or, type info() for more options.

| Type pbinom(5,1000,.01) at the R prompt.

> pbinom(5,1000,.01)
[1] 0.06613951

| You are quite good my friend!

  |===============================================================================================       |  93%

| Now use the function ppois with quantile equal to 5 and lambda equal to n*p to see if you get a similar
| result.

> ppois(2, lambda = 1000 * 0.01)
[1] 0.002769396

| Nice try, but that's not exactly what I was hoping for. Try again. Or, type info() for more options.

| Type ppois(5,1000*.01) at the R prompt.

> ppois(5, lambda = 1000 * 0.01)
[1] 0.06708596

| Nice work!

  |=================================================================================================     |  95%

| See how they're close? Pretty cool, right? This worked because n was large (1000) and p was small (.01).

...

  |====================================================================================================  |  98%

| Congrats! You've concluded this uncommon lesson on common distributions.

...

  |======================================================================================================| 100%

| Asymptotics. (Slides for this and other Data Science courses may be found at github
| https://github.com/DataScienceSpecialization/courses/. If you care to use them, they must be downloaded as a
| zip file and viewed locally. This lesson corresponds to 07_Statistical_Inference/07_Asymptopia.)

...

  |=                                                                                                     |   1%

| In this lesson, we'll discuss asymptotics, a topic which describes how statistics behave as sample sizes get
| very large and approach infinity. Pretending sample sizes and populations are infinite is useful for making
| statistical inferences and approximations since it often leads to a nice understanding of procedures.

...

  |===                                                                                                   |   3%

| Asymptotics generally give no assurances about finite sample performance, but they form the basis for
| frequency interpretation of probabilities (the long run proportion of times an event occurs).

...

  |====                                                                                                  |   4%

| Recall our simulations and discussions of sample means in previous lessons. We can now talk about the
| distribution of sample means of a collection of iid observations. The mean of the sample mean estimates what?

1: standard error
2: sigma^2/n
3: population variance
4: population mean

Selection: 4

| That's a job well done!

  |======                                                                                                |   5%

| The Law of Large Numbers (LLN) says that the average (mean) approaches what it's estimating. We saw in our
| simulations that the larger the sample size the better the estimation.  As we flip a fair coin over and over,
| it eventually converges to the true probability of a head (.5).

...

  |=======                                                                                               |   7%

| The LLN forms the basis of frequency style thinking.

...

  |========                                                                                              |   8%

| To see this in action, we've copied some code from the slides and created the function coinPlot. It takes an
| integer n which is the number of coin tosses that will be simulated. As coinPlot does these coin flips it
| computes the cumulative sum (assuming heads are 1 and tails 0), but after each toss it divides the cumulative
| sum by the number of flips performed so far. It then plots this value for each of the k=1...n tosses. Try it
| now for n=10.

> coinPlot(10)

| You got it!

  |==========                                                                                            |  10%

| Your output depends on R's random number generator, but your plot probably jumps around a bit and, by the
| 10th flip, your cumulative sum/10 is probably different from mine. If you did this several times, your plots
| would vary quite a bit. Now call coinPlot again, this time with 10000 as the argument.

> coinPlot(10000)

| Excellent job!

  |===========                                                                                           |  11%

| See the difference? Asymptotics in Action! The line approaches its asymptote of .5. This is the probability
| you expect since what we're plotting, the cumulative sum/number of flips, represents the probability of the
| coin landing on heads. As we know, this is .5 .

...

  |=============                                                                                         |  12%

| We say that an estimator is CONSISTENT if it converges to what it's trying to estimate. The LLN says that the
| sample mean of iid samples is consistent for the population mean. This is good, right?

...

  |==============                                                                                        |  14%

| Based on our previous lesson do you think the sample variance (and hence sample deviation) are consistent as
| well?

1: Yes
2: No

Selection: 1

| Your dedication is inspiring!

  |===============                                                                                       |  15%

| Now for something really important - the CENTRAL LIMIT THEOREM (CLT) - one of the most important theorems in
| all of statistics. It states that the distribution of averages of iid variables (properly normalized) becomes
| that of a standard normal as the sample size increases.

...

  |=================                                                                                     |  16%

| Let's dissect this to see what it means. First, 'properly normalized' means that you transformed the sample
| mean X'. You subtracted the population mean mu from it and divided the difference by sigma/sqrt(n). Here
| sigma is the standard deviation of the population and n is the sample size.

...

  |==================                                                                                    |  18%

| Second, the CLT says that for large n, this normalized variable, (X'-mu)/(sigma/sqrt(n)) is almost normally
| distributed with mean 0 and variance 1. Remember that n must be large for the CLT to apply.

...

  |====================                                                                                  |  19%

| Do you recognize sigma/sqrt(n) from our lesson on variance? Since the population std deviation sigma is
| unknown, sigma/sqrt(n) is often approximated by what?

1: the variance of the population
2: the standard error of the sample mean
3: I give up
4: the mean of the population

Selection: 2

| Nice work!

  |=====================                                                                                 |  21%

| Let's rephrase the CLT. Suppose X_1, X_2, ... X_n are independent, identically distributed random variables
| from an infinite population with mean mu and variance sigma^2. Then if n is large, the mean of the X's, call
| it X', is approximately normal with mean mu and variance sigma^2/n. We denote this as X'~N(mu,sigma^2/n).

...

  |======================                                                                                |  22%

| To show the CLT in action consider this figure from the slides. It presents 3 histograms of 1000 averages of
| dice rolls with sample sizes of 10, 20 and 30 respectively. Each average of n dice rolls (n=10,20,30) has
| been normalized by subtracting off the mean (3.5) then dividing by the standard error, sqrt(2.92/n). The
| normalization has made each histogram look like a standard normal, i.e., mean 0 and standard deviation 1.

...

  |========================                                                                              |  23%

| Notice that the CLT said nothing about the original population being normally distributed. That's precisely
| where its usefulness lies! We can assume normality of a sample mean no matter what kind of population we
| have, as long as our sample size is large enough and our samples are independent. Let's look at how it works
| with a binomial experiment like flipping a coin.

...

  |=========================                                                                             |  25%

| Recall that if the probability of a head (call it 1) is p, then the probability of a tail (0) is 1-p. The
| expected value then is p and the variance is p-p^2 or p(1-p). Suppose we do n coin flips and let p' represent
| the average of these n flips. We normalize p' by subtracting the mean p and dividing by the std deviation
| sqrt(p(1-p)/n). Let's do this for 1000 trials and plot the resulting histogram.

...

  |===========================                                                                           |  26%

| Here's a figure from the slides showing the results of 3 such trials where each trial is for a different
| value of n (10, 20, and 30) and the coin is fair,so E(X)=.5 and the standard error is 1/(2sqrt(n)). Notice
| how with larger n (30) the histogram tightens up around the mean 0.

...

  |============================                                                                          |  27%

| Here's another plot from the slides of the same experiment, this time using a biassed coin. We set the
| probability of a head to .9, so E(X)=.9 and the standard error is sqrt(.09/n) Again, the larger the sample
| size the more closely the distribution looks normal, although with this biassed coin the normal approximation
| isn't as good as it was with the fair coin.

...

  |=============================                                                                         |  29%

| Now let's talk about confidence intervals.

...

  |===============================                                                                       |  30%

| We know from the CLT that for large n, the sample mean is normal with mean mu and standard deviation
| sigma/sqrt(n). We also know that 95% of the area under a normal curve is within two standard deviations of
| the mean. This figure, a standard normal with mu=0 and sigma=1, illustrates this point; the entire shaded
| portion depicts the area within 2 standard deviations of the mean and the darker portion shows the 68% of the
| area within 1 standard deviation.

...

  |================================                                                                      |  32%

| It follows that 5% of the area under the curve is not shaded. By symmetry of the curve, only 2.5% of the data
| is greater than the mean + 2 standard deviations (mu+2*sigma/sqrt(n)) and only 2.5% is less than the mean - 2
| standard deviations (mu-2*sigma/sqrt(n)).

...

  |==================================                                                                    |  33%

| So the probability that the sample mean X' is bigger than mu + 2sigma/sqrt(n) OR smaller than
| mu-2sigma/sqrt(n) is 5%.  Equivalently, the probability of being between these limits is 95%. Of course we
| could have different sizes of intervals. If we wanted something other than 95, then we would use a quantile
| other than 2.

...

  |===================================                                                                   |  34%

| The quantity X' plus or minus 2 sigma/sqrt(n) is called a 95% interval for mu. The 95% says that if one were
| to repeatedly get samples of size n, about 95% of the intervals obtained would contain mu, the quantity we're
| trying to estimate.

...

  |====================================                                                                  |  36%

| Note that for a 95% confidence interval we divide (100-95) by 2 (since we have both left and right tails) and
| add the result to 95 to compute the quantile we need. The 97.5 quantile is actually 1.96, but for simplicity
| it's often just rounded up to 2. If you wanted to find a 90% confidence interval what quantile would you
| want?

1: 100
2: 90
3: 85
4: 95

Selection: 4

| You are really on a roll!

  |======================================                                                                |  37%

| Use the R function qnorm to find the 95th quantile for a standard normal distribution. Remember that qnorm
| takes a probability as an input. You can use default values for all the other arguments.

> qnorm(95)
[1] NaN
Warning message:
In qnorm(95) : NaNs produced

| One more time. You can do it! Or, type info() for more options.

| Type qnorm(.95) at the command prompt.

> qnorm(.95)
[1] 1.644854

| Great job!

  |=======================================                                                               |  38%

| As we've seen before, in a binomial distribution in which p represents the probability or proportion of
| success, the variance sigma^2 is p(1-p), so the standard error of the sample mean p' is sqrt(p(1-p)/n) where
| n is the sample size. The 95% confidence interval of p is then p' +/- 2*sqrt(p(1-p)/n). The 2 in this formula
| represents what?

1: the standard error of p'
2: the approximate 97.5% normal quantile
3: the mean of p'
4: the variance of p'

Selection: 2

| Nice work!

  |=========================================                                                             |  40%

| A critical point here is that we don't know the true value of p; that's what we're trying to estimate. How
| can we compute a confidence interval if we don't know p(1-p)? We could be conservative and try to maximize it
| so we get the largest possible confidence interval. Calculus tells us that p(1-p) is maximized when p=1/2, so
| we get the biggest 95% confidence interval when we set p=1/2 in the formula p'+/- 2*sqrt(p(1-p)/n).

...

  |==========================================                                                            |  41%

| Using 1/2 for the value of p in the formula above yields what expression for the 95% confidence interval for
| p?

1: p'+/- 2*sqrt(n)
2: p'+/- 1/(2*sqrt(n))
3: p'+/- 1/sqrt(n)

Selection: 3

| Great job!

  |===========================================                                                           |  42%

| Here's another example of applying this formula from the slides. Suppose you were running for office and your
| pollster polled 100 people. Of these 60 claimed they were going to vote for you. You'd like to estimate the
| true proportion of people who will vote for you and you want to be 95% confident of your estimate. We need to
| find the limits that will contain the true proportion of your supporters with 95% confidence, so we'll use
| the formula p' +/- 1/sqrt(n) to answer this question. First, what value would you use for p', the sampled
| estimate?

1: .56
2: 1.00
3: .60
4: .10

Selection: 3

| Keep up the great work!

  |=============================================                                                         |  44%

| What would you use for 1/sqrt(n)?

1: 1/100
2: 1/sqrt(56)
3: 1/10
4: 1/sqrt(60)

Selection: 3

| Nice work!

  |==============================================                                                        |  45%

| The bounds of the interval then are what?

1: .55 and .65
2: .46 and .66
3: .5 and .7
4: I haven't a clue

Selection: 1

| That's not exactly what I'm looking for. Try again.

| We know p'- 1/sqrt(n) is the lower bound and p'+ 1/sqrt(n) is the upper bound, so use the answers from the
| two previous answers to fill in values for these variables.

1: .5 and .7
2: I haven't a clue
3: .55 and .65
4: .46 and .66

Selection: 1

| Great job!

  |================================================                                                      |  47%

| How do you feel about the election?

1: unsure
2: Perseverance, that's the answer
3: confident
4: I'll pull out

Selection: 3

| Great job!

  |=================================================                                                     |  48%

| Another technique for calculating confidence intervals for binomial distributions is to replace p with p'.
| This is called the Wald confidence interval. We can also use the R function qnorm to get a more precise
| quantile value (closer to 1.96) instead of our ballpark estimate of 2.

...

  |==================================================                                                    |  49%

| With the formula p'+/- qnorm(.975)*sqrt(p'(1-p')/100), use the p' and n values from above and the R construct
| p'+c(-1,1)... to handle the plus/minus portion of the formula. You should see bounds similar to the ones you
| just estimated.

> 0.6 + c(-1,1) * qnorm(.975)*sqrt((0.6*0.4)/100)
[1] 0.5039818 0.6960182

| Almost! Try again. Or, type info() for more options.

| Type .6 + c(-1,1)*qnorm(.975)*sqrt(.6*.4/100) at the command prompt.

> .6 + c(-1,1)*qnorm(.975)*sqrt(.6*.4/100)
[1] 0.5039818 0.6960182

| Excellent work!

  |====================================================                                                  |  51%

| As an alternative to this Wald interval, we can also use the R function binom.test with the parameters 60 and
| 100 and let all the others default. This function "performs an exact test of a simple null hypothesis about
| the probability of success in a Bernoulli experiment." (This means it guarantees the coverages, uses a lot of
| computation and doesn't rely on the CLT.) This function returns a lot of information but all we want now are
| the values of the confidence interval that it returns. Use the R construct x$conf.int to find these now.

> binom.test(60,100)$conf.int
[1] 0.4972092 0.6967052
attr(,"conf.level")
[1] 0.95

| That's correct!

  |=====================================================                                                 |  52%

| Close to what we've seen before, right? Now we're going to see that the Wald interval isn't very accurate
| when n is small. We'll use the example from the slides.

...

  |======================================================                                                |  53%

| Suppose we flip a coin a small number of times, say 20. Also suppose we have a function mywald which takes a
| probability p, and generates 30 sets of 20 coin flips using that probability p. It uses the sampled
| proportion of success, p', for those 20 coin flips to compute the upper and lower bounds of the 95% Wald
| interval, that is, it computes the two numbers p'+/- qnorm(.975) * sqrt(p' * (1-p') / n) for each of the 30
| trials. For the given true probability p, we count the number of times out of those 30 trials that the true
| probability p was in the Wald confidence interval. We'll call this the coverage.

...

  |========================================================                                              |  55%

| To make sure you understand what's going on, try running mywald now with the probability .2. It will print
| out 30 p' values (which you don't really need to see), followed by 30 lower bounds, 30 upper bounds and
| lastly the percentage of times that the input .2 was between the two bounds. See if you agree with the
| percentage you get. Usually it suffices to just count the number of times (out of the 30) that .2 is less
| than the upper bound.

> mywald(p = .2)
[1] "Here are the p' values"
 [1] 0.20 0.35 0.20 0.15 0.20 0.20 0.25 0.25 0.20 0.30 0.15 0.05 0.00 0.25 0.10 0.10 0.20 0.15 0.20 0.20 0.15
[22] 0.20 0.20 0.35 0.05 0.20 0.10 0.25 0.00 0.25
[1] "Here are the lower"
 [1]  0.024695492  0.140962697  0.024695492 -0.006490575  0.024695492  0.024695492  0.060227303  0.060227303
 [9]  0.024695492  0.099163455 -0.006490575 -0.045516829  0.000000000  0.060227303 -0.031478381 -0.031478381
[17]  0.024695492 -0.006490575  0.024695492  0.024695492 -0.006490575  0.024695492  0.024695492  0.140962697
[25] -0.045516829  0.024695492 -0.031478381  0.060227303  0.000000000  0.060227303
[1] "Here are the upper"
 [1] 0.3753045 0.5590373 0.3753045 0.3064906 0.3753045 0.3753045 0.4397727 0.4397727 0.3753045 0.5008365
[11] 0.3064906 0.1455168 0.0000000 0.4397727 0.2314784 0.2314784 0.3753045 0.3064906 0.3753045 0.3753045
[21] 0.3064906 0.3753045 0.3753045 0.5590373 0.1455168 0.3753045 0.2314784 0.4397727 0.0000000 0.4397727
[1] 0.8666667

| That's correct!

  |=========================================================                                             |  56%

| Now that you understand the underlying principle, suppose instead of 30 trials, we used 1000 trials. Also
| suppose we did this experiment for a series of probabilities, say from .1 to .9 taking steps of size .05.
| More specifically, we'll call our function using 17 different probabilities, namely .1, .15, .2, .25, ... .9
| . We can then plot the percentages of coverage for each of the probabilities.

...

  |===========================================================                                           |  58%

| Here's the plot of our results. Each of the 17 vertices show the percentage of coverage for a particular true
| probability p passed to the function. Results will vary, but usually the only probability that hits close to
| or above the 95% line is the p=.5 . So this shows that when n, the number of flips, is small (20) the CLT
| doesn't hold for many values of p, so the Wald interval doesn't work very well.

...

  |============================================================                                          |  59%

| Let's try the same experiment and increase n, the number of coin flips in each of our 1000 trials, from 20 to
| 100 to see if the plot improves. Again, results may vary, but all the probabilities are much closer to the
| 95% line, so the CLT works better with a bigger value of n.

...

  |=============================================================                                         |  60%

| A quick fix to the problem of having a small n is to use the Agresti/Coull interval. This simply means we add
| 2 successes and 2 failures to the counts when calculating the proportion p'. Specifically, if X is the number
| of successes out of the 20 coin flips, then instead of setting p'=X/20, let p'=(X+2)/24. We use 24 as the
| number of trials since we've added 2 successes and 2 failures to the counts. Note that we still use 20 in the
| calculation of the upper and lower bounds.

...

  |===============================================================                                       |  62%

| Here's a plot using this Agresti/Coull interval, with 1000 trials of 20 coin flips each. It looks much better
| than both the original Wald with 20 coin flips and the improved Wald with 100 coin flips. However, this
| technique might make the confidence interval too wide.

...

  |================================================================                                      |  63%

| Why does this work? Adding 2 successes and 2 failures pulls p' closer to .5 which, as we saw, is the value
| which maximizes the confidence interval.

...

  |==================================================================                                    |  64%

| To show this simply, we wrote a function ACCompar, which takes an integer input n. For each k from 1 to n it
| computes two fractions, k/n and (k+2)/(n+4). It then prints out the boolean vector of whether the new
| (k+2)/(n+4) fraction is less than the old k/n. It also prints out the total number of k's for which the
| condition is TRUE.

...

  |===================================================================                                   |  66%

| For all k less than n/2, you see FALSE indicating that the new fraction is greater than or equal to k/n. For
| all k greater than n/2 you see TRUE indicating that the new fraction is less than the old. If k=n/2 the old
| and new fractions are equal.

...

  |====================================================================                                  |  67%

| Try running ACCompar now with an input of 20.

> ACCompar(20)
 [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
[19]  TRUE  TRUE
[1] 10

| Your dedication is inspiring!

  |======================================================================                                |  68%

| Let's move on to Poisson distributions and confidence intervals. Recall that Poisson distributions apply to
| counts or rates. For the latter, we write X~Poisson(lambda*t) where lambda is the expected count per unit of
| time and t is the total monitoring time.

...

  |=======================================================================                               |  70%

| Here's another example from the slides. Suppose a nuclear pump failed 5 times out of 94.32 days and we want a
| 95% confidence interval for the failure rate per day. The number of failures X is Poisson distributed with
| parameter (lambda*t). We don't observe the failure rate, but we estimate it as x/t. Call our estimate
| lambda_hat, so lambda_hat=x/t. According to theory, the variance of our estimated failure rate is lambda/t.
| Again, we don't observe lamdba, so we use our estimate of it instead. We thus approximate the variance of
| lambda_hat as lambda_hat/t.

...

  |=========================================================================                             |  71%

| In this example what would you use as the estimated mean x/t?

1: 94.32/5
2: 5/94.32
3: I haven't a clue

Selection: 2

| Perseverance, that's the answer.

  |==========================================================================                            |  73%

| Set a variable lamb now with this value.

> lamb <- 5/94.32

| That's correct!

  |===========================================================================                           |  74%

| So lamb is our estimated mean and lamb/t is our estimated variance. The formula we've used to calculate a 95%
| confidence interval is est mean + c(-1,1)*qnorm(.975)*sqrt(est var). Use this formula now making the
| appropriate substitutions.

> lamb + c(-1,1) *qnorm(.975)*sqrt(lamb/5)
[1] -0.1488006  0.2548227

| Almost! Try again. Or, type info() for more options.

| Type lamb +c(-1,1)*qnorm(.975)*sqrt(lamb/94.32) at the R prompt.

> lamb + c(-1,1) *qnorm(.975)*sqrt(lamb/94.32)
[1] 0.006545667 0.099476386

| Great job!

  |=============================================================================                         |  75%

| As a check we can use R's function poisson.test with the arguments 5 and 94.32 to check this result. This is
| an exact test so it guarantees coverage. As with the binomial exact test, we only need to look at the conf
| portion of the result using the x$conf construct. Do this now.

> poisson.test(5,94.32)$conf
[1] 0.01721254 0.12371005
attr(,"conf.level")
[1] 0.95

| That's correct!

  |==============================================================================                        |  77%

| Pretty close, right? Now to check the coverage of our estimate we'll run the same simulation experiment we
| ran before with binomial distributions. We'll vary our lambda values from .005 to .1 with steps of .01 (so we
| have 10 of them), and for each one we'll generate 1000 Poisson samples with mean lambda*t. We'll calculate
| sample means and use them to compute 95% confidence intervals. We'll then count how often out of the 1000
| simulations the true mean (our lambda) was contained in the computed interval.

...

  |================================================================================                      |  78%

| Here's a plot of the results. We see that the coverage improves as lambda gets larger, and it's quite off for
| small lambda values.

...

  |=================================================================================                     |  79%

| Now it's interesting to see how the coverage improves when we increase the unit of time. In the previous plot
| we used t=100 (rounding the 94.32 up). Here's a plot of the same experiment setting t=1000. We see that the
| coverage is much better for almost all the values of lambda, except for the smallest ones.

...

  |==================================================================================                    |  81%

| Now for a quick review!

...

  |====================================================================================                  |  82%

| What tells us that averages of iid samples converge to the population means that they are estimating?

1: the BLT
2: the law of large numbers
3: the law of small numbers
4: the CLT

Selection: 4

| Almost! Try again.

| Think Big!

1: the law of small numbers
2: the CLT
3: the BLT
4: the law of large numbers

Selection: 2

| Give it another try.

| Think Big!

1: the law of small numbers
2: the BLT
3: the CLT
4: the law of large numbers

Selection: 4

| That's the answer I was looking for.

  |=====================================================================================                 |  84%

| What tells us that averages are approximately normal for large enough sample sizes

1: the CLT
2: the law of small numbers
3: the law of large numbers
4: the BLT

Selection: 1

| Keep working like that and you'll get there!

  |=======================================================================================               |  85%

| The Central Limit Theorem (CLT) tells us that averages have what kind of distributions?

1: binomial
2: Poisson
3: normal
4: abnormal

Selection: 3

| That's a job well done!

  |========================================================================================              |  86%

| The Central Limit Theorem (CLT) tells us that averages have normal distributions centered at what?

1: the standard error
2: the population mean
3: the population variance

Selection: 2

| Excellent work!

  |=========================================================================================             |  88%

| The Central Limit Theorem (CLT) tells us that averages have normal distributions with standard deviations
| equal to what?

1: the standard error
2: the population variance
3: the population mean

Selection: 2

| Not quite right, but keep trying.

| Which choice has the word standard in it?

1: the population variance
2: the population mean
3: the standard error

Selection: 3

| Keep working like that and you'll get there!

  |===========================================================================================           |  89%

| True or False - The Central Limit Theorem (CLT) tells us that averages always have normal distributions no
| matter how big the sample size

1: False
2: True

Selection: 1

| You are amazing!

  |============================================================================================          |  90%

| To calculate a confidence interval for a mean you take the sample mean and add and subtract the relevant
| normal quantile times the what?

1: standard error
2: variance
3: mean
4: variance/n

Selection: 2

| That's not exactly what I'm looking for. Try again.

| You want something like a standard deviation, right? Which choice has the word standard in it?

1: variance
2: mean
3: variance/n
4: standard error

Selection: 3

| That's not exactly what I'm looking for. Try again.

| You want something like a standard deviation, right? Which choice has the word standard in it?

1: variance
2: mean
3: variance/n
4: standard error

Selection: 4

| Keep working like that and you'll get there!

  |==============================================================================================        |  92%

| For a 95% confidence interval approximately how many standard errors would you add and subtract from the
| sample mean?

1: 6
2: 4
3: 8
4: 2

Selection: 4

| You are amazing!

  |===============================================================================================       |  93%

| If you wanted increased coverage what would you do to your confidence interval?

1: increase it
2: decrease it
3: keep it the same

Selection: 
Enter an item from the menu, or 0 to exit
Selection: 1

| Great job!

  |================================================================================================      |  95%

| If you had less variability in your data would your confidence interval get bigger or smaller?

1: bigger
2: smaller

Selection: 1

| Not exactly. Give it another go.

| Recall the size of the confidence interval positively depends on standard error which is sqrt(var/n). If
| variance is smaller then so is variability and the interval.

1: smaller
2: bigger

Selection: 2

| Not exactly. Give it another go.

| Recall the size of the confidence interval positively depends on standard error which is sqrt(var/n). If
| variance is smaller then so is variability and the interval.

1: bigger
2: smaller

Selection: 2

| You are doing so well!

  |==================================================================================================    |  96%

| If you had larger sample size would your confidence interval get bigger or smaller?

1: bigger
2: smaller

Selection: 2

| Perseverance, that's the answer.

  |===================================================================================================   |  97%

| A quick fix for small sample size binomial calculations is what?

1: add 2 successes and subtract 2 failures
2: add 2 successes and 2 failures
3: add 2 successes and 4 failures
4: changing data seem dishonest

Selection: 2

| Great job!

  |===================================================================================================== |  99%

| Congrats! You've concluded this lesson on asymptotics. We hope you feel confident and are asymptomatic after
| going through it.

...

  |======================================================================================================| 100%


| Great job!

  |====================================================================================================  |  98%

| Congrats! You've concluded this vary long lesson on variance. We hope you liked it vary much.

...

  |======================================================================================================| 100%




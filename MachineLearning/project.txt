

The goal of your project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set. You may use any of the other variables to predict with. You should create a report describing how you built your model, how you used cross validation, what you think the expected out of sample error is, and why you made the choices you did. You will also use your prediction model to predict 20 different test cases.

http://machinelearningmastery.com/feature-selection-with-the-caret-r-package/

Background

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement – a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

http://groupware.les.inf.puc-rio.br/har
http://groupware.les.inf.puc-rio.br/public/papers/2013.Velloso.QAR-WLE.pdf


Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).

4 sensors:
- belt
- arm
- dumbbell
- forearm

For feature extraction we used a sliding window approach
with different lengths from 0.5 second to 2.5 seconds, with
0.5 second overlap. In each step of the sliding window approach
we calculated features on the Euler angles (roll, pitch
and yaw), as well as the raw accelerometer, gyroscope and
magnetometer readings. For the Euler angles of each of the
four sensors we calculated eight features: mean, variance,
standard deviation, max, min, amplitude, kurtosis and skewness,
generating in total 96 derived feature sets.

In order to identify the most relevant features we used the
feature selection algorithm based on correlation proposed by
Hall [14]. The algorithm was configured to use a “Best First”
strategy based on backtracking.

[14] M. A. Hall. Correlation-based Feature Subset Selection for Machine Learning. PhD thesis, Department of
Computer Science, University of Waikato, Hamilton,
New Zealand, Apr. 1999.

http://www.cs.waikato.ac.nz/~mhall/thesis.pdf



17 features were selected:
in the belt, were selected the mean and variance of the roll,
maximum, range and variance of the accelerometer vector,
variance of the gyro and variance of the magnetometer. In
the arm, the variance of the accelerometer vector and the
maximum and minimum of the magnetometer were selected.
In the dumbbell, the selected features were the maximum of
the acceleration, variance of the gyro and maximum and
minimum of the magnetometer, while in the glove, the sum
of the pitch and the maximum and minimum of the gyro
were selected.


https://www.r-project.org/nosvn/conferences/useR-2013/Tutorials/kuhn/user_caret_2up.pdf


The data is a time series of sequences of readings: a number of readings through an exercise repetition by a particular person.
The testing set only has single readings at a point in time, rather than a complete repetition time series.
It would be more valuable to predict whether a given sequence of readings indicates what type of repetition (classe) was being performed, rather than predicting based on a single reading.

But given the test set, we will focus on predictions based on single readings at points in time.


# full training data set

train <- read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!", ""))
train$classe <- factor(train$classe)

19622 obs. of  160 variables

# columns that are not completely NA

nonEmptytrain <-train[,colSums(is.na(train)) != nrow(train)]

19622 obs. of  154 variables

# columns that have complete data - no NA's

allValuesOnlytrain <-train[,colSums(is.na(train)) == 0]

19622 obs. of  60 variables

columns 1:7 are categorical data to support order and time sequencing. The only exception is the User_name.



length(names(train))
160

There are numbers of empty columns, like:

skewness_yaw_forearm
        :19216
 #DIV/0!:  406     
 
 amplitude_yaw_forearm
        :19216
 #DIV/0!:   84
 0.00   :  322
 
 Or with minimal data:
 
  max_yaw_belt
       :19216
-1.1   :   30
-1.4   :   29
-1.2   :   26
-0.9   :   24
-1.3   :   22
(Other):  275

var_accel_forearm
 Min.   :  0.000 
 1st Qu.:  6.759 
 Median : 21.165 
 Mean   : 33.502 
 3rd Qu.: 51.240 
 Max.   :172.606 
 NA's   :19216   

kurtosis_roll_forearm
       :19216        
#DIV/0!:   84        
-0.8079:    2        
-0.9169:    2        
-0.0227:    1        
-0.0359:    1        
(Other):  316        


 
 
 forearmMetrics <- summary(dplyr::select(train, contains("_forearm")))
 forearmMetricsF <- tbl_df(forearmMetrics)
 
 emptyForearmMetrics <- filter(forearmMetricsF, grepl("       :", as.character(n)))
 ?
 
emptyMetrics <- dplyr::filter(tbl_df(summary(train)), 
    grepl("       :.*", as.character(n)) | 
    grepl("#DIV/0!:.*", as.character(n)) |
    grepl("^0\\.0+ +:.*", as.character(n))
)

NAs <- dplyr::filter(tbl_df(summary(train)), 
    grepl("NA's   :.*", as.character(n)
)

head(as.POSIXlt(as.numeric(train$raw_timestamp_part_1),origin="1970-01-01",tz="GMT"))
[1] "2011-12-05 11:23:51 GMT" "2011-12-05 11:23:51 GMT" "2011-12-05 11:23:51 GMT" "2011-12-05 11:23:52 GMT"
[5] "2011-12-05 11:23:52 GMT" "2011-12-05 11:23:52 GMT"

raw_timestamp_part_2: millionths of a second
new_window
num_window

Plan:
- remove columns which only have no information: blanks, 0.00, #DIV/0! for all rows
- impute NAs?

Cross validation Approach:

* Use the training set
* Split it into training/test sets
* Build a model on the training set
* Evaluate on the test set
* Repeat and average the estimated errors

Used for:

* Picking variables to include in a model
* Picking the type of prediction function to use
* Picking the parameters in the prediction function
* Comparing different predictors

Random subsampling
k-Fold
leave 1 out

ie.

set.seed(32323)
folds <- createFolds(y=spam$type,k=10, list=TRUE,returnTrain=TRUE)

or

folds <- createResample(y=spam$type,times=10, list=TRUE)


For k-fold cross validation
* Larger k = less bias, more variance
* Smaller k = more bias, less variance
Random sampling must be done without replacement
Random sampling with replacement is the bootstrap
* Underestimates of the error
* Can be corrected, but it is complicated (0.632 Bootstrap)
If you cross-validate to pick predictors estimate, you must estimate errors on independent data.


Metric options
Continous outcomes:
* RMSE = Root mean squared error
* RSquared = R2 from regression models

Categorical outcomes:
* Accuracy = Fraction correct
* Kappa = A measure of concordance



trainControl resampling

method
* boot = bootstrapping
* boot632 = bootstrapping with adjustment
* cv = cross validation
* repeatedcv = repeated cross validation
* LOOCV = leave one out cross validation
number
* For boot/cross validation
* Number of subsamples to take
repeats
* Number of times to repeate subsampling
* If big this can slow things down


train_control <- trainControl(method="cv", number=10)

focusTrain <- dplyr::select(train, user_name, 8:ncol(train))

set.seed(20160828)
inTrain = createDataPartition(y=focusTrain$classe, p=0.75, list=FALSE)
focusTrainset = focusTrain[inTrain,]
focusTestset = focusTrain[-inTrain,]


nonEmptyFocusTrain <- dplyr::select(nonEmptytrain, user_name, 8:ncol(nonEmptytrain))

set.seed(20160828)
inTrain = createDataPartition(y=nonEmptyFocusTrain$classe, p=0.75, list=FALSE)
nonEmptyFocusTrainset = nonEmptyFocusTrain[inTrain,]
nonEmptyFocusTestset = nonEmptyFocusTrain[-inTrain,]

allValuesOnlyFocusTrain <- dplyr::select(allValuesOnlytrain, user_name, 8:ncol(allValuesOnlytrain))

set.seed(20160828)
inTrain = createDataPartition(y=allValuesOnlyFocusTrain$classe, p=0.75, list=FALSE)
allValuesOnlyFocusTrainset = allValuesOnlyFocusTrain[inTrain,]
allValuesOnlyFocusTestset = allValuesOnlyFocusTrain[-inTrain,]


library(rpart)

# since classe is a factor, rpart method = "class"

set.seed(20160828)
rpartModel <- rpart(classe ~ ., data=focusTrainset)
set.seed(20160828)
nonEmptyRpartModel <- rpart(classe ~ ., data=nonEmptyFocusTrainset)
set.seed(20160828)
#allValuesOnlyRpartModel <- rpart(classe ~ ., data=allValuesOnlyFocusTrainset)

allValuesOnlyRpartModel <- train(classe ~ ., data=allValuesOnlyFocusTrainset,
                 method="rpart")

By default, rpart will conduct as many splits as possible, then use 10–fold
cross–validation to prune the tree.

library(rpart.plot)

library(partykit)
rparty <- as.party(rpartModel)
plot(rparty)


printcp(rpartModel)
printcp(nonEmptyRpartModel)
printcp(allValuesOnlyRpartModel)

Classification tree:
rpart(formula = classe ~ ., data = allValuesOnlyFocusTrainset)

Variables actually used in tree construction:
 [1] accel_dumbbell_y     accel_dumbbell_z     accel_forearm_x      magnet_arm_y         magnet_belt_z       
 [6] magnet_dumbbell_y    magnet_dumbbell_z    magnet_forearm_z     pitch_belt           pitch_forearm       
[11] roll_belt            roll_forearm         total_accel_dumbbell yaw_arm              yaw_belt            
[16] yaw_forearm         

Root node error: 10533/14718 = 0.71565

n= 14718 

         CP nsplit rel error  xerror      xstd
1  0.115352      0   1.00000 1.00000 0.0051957
2  0.059844      1   0.88465 0.88465 0.0055511
3  0.034748      4   0.70512 0.74347 0.0057471
4  0.029431      5   0.67037 0.65898 0.0057496
5  0.020744      6   0.64094 0.62660 0.0057282
6  0.019747     12   0.49634 0.50033 0.0055220
7  0.018988     13   0.47660 0.47888 0.0054666
8  0.017089     14   0.45761 0.46350 0.0054229
9  0.013766     15   0.44052 0.44641 0.0053705
10 0.012912     18   0.39922 0.43729 0.0053408
11 0.012152     19   0.38631 0.42789 0.0053089
12 0.011393     20   0.37416 0.41555 0.0052649
13 0.010633     21   0.36276 0.39865 0.0052010
14 0.010348     22   0.35213 0.37786 0.0051160
15 0.010000     23   0.34178 0.36333 0.0050523


set.seed(20160828)

allValuesOnlyRpartPrediction <- predict(allValuesOnlyRpartModel, allValuesOnlyFocusTestset, type="class")

allValuesOnlyRpartConfusionMatrix <- confusionMatrix(allValuesOnlyRpartPrediction, allValuesOnlyFocusTestset$classe)


Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1270  139   13   48    9
         B   31  551   72   70   74
         C   49  101  704  123  114
         D   19   63   48  508   56
         E   26   95   18   55  648

Overall Statistics
                                          
               Accuracy : 0.7506          
                 95% CI : (0.7383, 0.7627)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.684           
 Mcnemar's Test P-Value : < 2.2e-16       

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9104   0.5806   0.8234   0.6318   0.7192
Specificity            0.9404   0.9375   0.9044   0.9546   0.9515
Pos Pred Value         0.8587   0.6905   0.6453   0.7320   0.7696
Neg Pred Value         0.9635   0.9031   0.9604   0.9297   0.9377
Prevalence             0.2845   0.1935   0.1743   0.1639   0.1837
Detection Rate         0.2590   0.1124   0.1436   0.1036   0.1321
Detection Prevalence   0.3016   0.1627   0.2225   0.1415   0.1717
Balanced Accuracy      0.9254   0.7591   0.8639   0.7932   0.8354



prediction1 <- predict(model1, subTesting, type = "class")

rpartModel <- rpart(classe ~ ., data=focusTrain)
nonEmptyRpartModel <- rpart(classe ~ ., data=nonEmptyFocusTrain)
allValuesOnlyRpartModel <- rpart(classe ~ ., data=allValuesOnlyFocusTrain)


names(focusTrain)[1:length(names(focusTrain)) - 1]

focusTest <- test[,names(focusTrain)[1:length(names(focusTrain)) - 1]]

rpartPrediction <- predict(rpartModel, focusTest, type = "class")

Error: variables "kurtosis_roll_belt", "kurtosis_picth_belt", "skewness_roll_belt", "skewness_roll_belt.1", "max_roll_belt", "max_picth_belt", "max_yaw_belt", "min_roll_belt", "min_pitch_belt", "min_yaw_belt", "amplitude_roll_belt", "amplitude_pitch_belt", "amplitude_yaw_belt", "var_total_accel_belt", "avg_roll_belt", "stddev_roll_belt", "var_roll_belt", "avg_pitch_belt", "stddev_pitch_belt", "var_pitch_belt", "avg_yaw_belt", "stddev_yaw_belt", "var_yaw_belt", "var_accel_arm", "avg_roll_arm", "stddev_roll_arm", "var_roll_arm", "avg_pitch_arm", "stddev_pitch_arm", "var_pitch_arm", "avg_yaw_arm", "stddev_yaw_arm", "var_yaw_arm", "kurtosis_roll_arm", "kurtosis_picth_arm", "kurtosis_yaw_arm", "skewness_roll_arm", "skewness_pitch_arm", "skewness_yaw_arm", "max_roll_arm", "max_picth_arm", "max_yaw_arm", "min_roll_arm", "min_pitch_arm", "min_yaw_arm", "amplitude_roll_arm", "amplitude_pitch_arm", "amplitude_yaw_arm", "kurtosis_roll_dumbbell", "kurtosis_picth_dumbbell", "skewness_roll_dumbbell


logisToConvert <- c("kurtosis_roll_belt", "kurtosis_picth_belt", "skewness_roll_belt", "skewness_roll_belt.1",
"max_roll_belt", "max_picth_belt", "max_yaw_belt", "min_roll_belt", "min_pitch_belt", "min_yaw_belt", 
"amplitude_roll_belt", "amplitude_pitch_belt", "amplitude_yaw_belt", "var_total_accel_belt", "avg_roll_belt",
"stddev_roll_belt", "var_roll_belt", "avg_pitch_belt", "stddev_pitch_belt", "var_pitch_belt", "avg_yaw_belt",
"stddev_yaw_belt", "var_yaw_belt", "var_accel_arm", "avg_roll_arm", "stddev_roll_arm", "var_roll_arm",
"avg_pitch_arm", "stddev_pitch_arm", "var_pitch_arm", "avg_yaw_arm", "stddev_yaw_arm", "var_yaw_arm",
"kurtosis_roll_arm", "kurtosis_picth_arm", "kurtosis_yaw_arm", "skewness_roll_arm", "skewness_pitch_arm",
"skewness_yaw_arm", "max_roll_arm", "max_picth_arm", "max_yaw_arm", "min_roll_arm", "min_pitch_arm", 
"min_yaw_arm", "amplitude_roll_arm", "amplitude_pitch_arm", "amplitude_yaw_arm", "kurtosis_roll_dumbbell",
"kurtosis_picth_dumbbell", "skewness_roll_dumbbell")

logisToConvert2 <- c("skewness_pitch_dumbbell", "max_roll_dumbbell", "max_picth_dumbbell", "max_yaw_dumbbell", "min_roll_dumbbell", "min_pitch_dumbbell", "min_yaw_dumbbell", "amplitude_roll_dumbbell", "amplitude_pitch_dumbbell", "amplitude_yaw_dumbbell", "var_accel_dumbbell", "avg_roll_dumbbell", "stddev_roll_dumbbell", "var_roll_dumbbell", "avg_pitch_dumbbell", "stddev_pitch_dumbbell", "var_pitch_dumbbell", "avg_yaw_dumbbell", "stddev_yaw_dumbbell", "var_yaw_dumbbell", "kurtosis_roll_forearm", "kurtosis_picth_forearm", "skewness_roll_forearm", "skewness_pitch_forearm", "max_roll_forearm", "max_picth_forearm", "max_yaw_forearm", "min_roll_forearm", "min_pitch_forearm", "min_yaw_forearm", "amplitude_roll_forearm", "amplitude_pitch_forearm", "amplitude_yaw_forearm", "var_accel_forearm", "avg_roll_forearm", "stddev_roll_forearm", "var_roll_forearm", "avg_pitch_forearm", "stddev_pitch_forearm", "var_pitch_forearm", "avg_yaw_forearm", "stddev_yaw_forearm", "var_yaw_forearm")


playTest[,logisToConvert] = sapply(playTest[,logisToConvert], as.numeric)
playTest[,logisToConvert2] = sapply(playTest[,logisToConvert2], as.numeric)
focusPlayTest <- playTest[,names(focusTrain)[1:length(names(focusTrain)) - 1]]
rpartPrediction <- predict(rpartModel, focusPlayTest, type="class")


nonEmptyFocusPlayTest <- playTest[,names(nonEmptytrain)[1:length(names(nonEmptytrain)) - 1]]
nonEmptyRpartPrediction <- predict(nonEmptyRpartModel, nonEmptyFocusPlayTest, type="class")

allValuesOnlyFocusPlayTest <- playTest[,names(allValuesOnlytrain)[1:length(names(allValuesOnlytrain)) - 1]]
allValuesOnlyRpartPrediction <- predict(allValuesOnlyRpartModel, allValuesOnlyFocusPlayTest, type="class")

> allValuesOnlyRpartPrediction
 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
 B  A  B  A  A  C  D  A  A  A  C  B  C  A  E  E  A  B  B  B 
Levels: A B C D E



library(doParallel)
cl <- makeCluster(detectCores())
registerDoParallel(cl)
controls <- trainControl(method="cv", number = 10)
nonEmptyRFModel <- train(classe ~ ., method = "rf", data=nonEmptyFocusTrain, trControl = controls, na.action = na.omit, allowParallel = TRUE)
nonEmptyRFPrediction <- predict(nonEmptyRFModel, nonEmptyFocusPlayTest)

 Error in predict.randomForest(modelFit, newdata) : nvarImewdata has 0 rows 
 
 
stopCluster(cl)

controls <- trainControl(method="cv", number = 6)
cl <- makeCluster(detectCores())
registerDoParallel(cl)
allValuesOnlyRFModel <- train(classe ~ ., method = "rf", data=allValuesOnlyFocusTrainset, trControl = controls, allowParallel = TRUE, importance = TRUE)
allValuesOnlyRFPrediction <- predict(allValuesOnlyRFModel, allValuesOnlyFocusTestset)
stopCluster(cl)


allValuesOnlyRFConfusionMatrix <- confusionMatrix(allValuesOnlyRFPrediction, allValuesOnlyFocusTestset$classe)

Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1393    6    0    0    0
         B    0  940    4    0    0
         C    1    3  849   13    1
         D    0    0    2  790    0
         E    1    0    0    1  900

Overall Statistics
                                          
               Accuracy : 0.9935          
                 95% CI : (0.9908, 0.9955)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9917          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9986   0.9905   0.9930   0.9826   0.9989
Specificity            0.9983   0.9990   0.9956   0.9995   0.9995
Pos Pred Value         0.9957   0.9958   0.9792   0.9975   0.9978
Neg Pred Value         0.9994   0.9977   0.9985   0.9966   0.9998
Prevalence             0.2845   0.1935   0.1743   0.1639   0.1837
Detection Rate         0.2841   0.1917   0.1731   0.1611   0.1835
Detection Prevalence   0.2853   0.1925   0.1768   0.1615   0.1839
Balanced Accuracy      0.9984   0.9948   0.9943   0.9910   0.9992

> varImp(allValuesOnlyRFModel)
rf variable importance

  variables are sorted by maximum importance across the classes
  only 20 most important variables shown (out of 57)

                         A     B     C     D      E
roll_belt            79.92 84.36 82.06 79.49 100.00
pitch_belt           34.21 93.57 63.27 48.45  41.20
pitch_forearm        56.64 74.93 90.82 60.64  61.73
magnet_dumbbell_y    69.01 61.83 85.31 65.75  55.93
magnet_dumbbell_z    76.84 57.35 68.30 52.36  52.37
yaw_belt             64.66 67.71 66.77 74.17  50.09
accel_forearm_x      24.65 40.50 38.31 54.38  42.33
roll_forearm         51.09 42.67 47.40 37.48  38.36
gyros_dumbbell_y     39.95 34.32 45.31 29.93  30.14
yaw_arm              44.57 33.47 29.94 34.30  23.79
gyros_belt_z         24.06 34.81 34.36 26.08  42.59
accel_dumbbell_y     37.37 35.08 42.28 34.45  35.31
accel_dumbbell_z     29.49 33.36 29.75 33.57  38.29
gyros_forearm_y      15.58 37.43 31.31 25.10  21.69
magnet_belt_y        22.74 36.38 31.70 26.61  31.85
roll_dumbbell        23.91 36.08 25.05 27.49  35.11
gyros_arm_y          32.08 35.43 25.79 34.26  24.90
magnet_belt_x        19.95 34.72 31.17 21.10  32.45
total_accel_dumbbell 19.17 33.53 22.43 27.62  30.83
magnet_forearm_z     33.34 31.34 28.92 27.50  32.11


predict(allValuesOnlyRFModel, nonEmptyFocusPlayTest)

 [1] B A B A A E D B A A B C B A E E A B B B
Levels: A B C D E


